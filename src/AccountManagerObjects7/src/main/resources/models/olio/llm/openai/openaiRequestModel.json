{
	"name": "olio.llm.openai.openaiRequest",
	"likeInherits": [
		"data.directory"
	],
	"inherits": [
		"common.groupExt",
		"common.baseLight",
		"olio.llm.request"
	],
	"description": "An OpenAI request model that defines the parameters for making requests to OpenAI's language models. This includes settings like temperature, max tokens, and the messages to be processed by the model.",
	"group": "Chat",
	"icon": "chat",
	"label": "Requests",
	"vector": "org.cote.accountmanager.olio.VectorProvider",
	"query": [
		"id",
		"groupId"
	],
	"fields": [
		{
			"name": "max_tokens",
			"type": "int",
			"default": 2048,
			"minValue": 0,
			"maxValue": 120000
		},
		{
			"name": "temperature",
			"type": "double",
			"default": 0.75
		},
		{
			"name": "top_p",
			"type": "double",
			"default": 0.5
		},
		{
			"name": "frequency_penalty",
			"type": "double",
			"default": 1.3
		},
		{
			"name": "presence_penalty",
			"type": "double",
			"default": 1.3
		},
		{
			"name": "messages",
			"type": "list",
			"baseType": "model",
			"baseModel": "olio.llm.openai.openaiMessage"
		}
	]
}